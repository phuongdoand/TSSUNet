{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad55fad7",
   "metadata": {},
   "source": [
    "# 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8225b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fde0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sigma70 = pd.read_csv(\"20211213.Sigma70.txt\", sep = '\\t', names = [\"name\", \"seq\", \"strand\", \"express\"])\n",
    "\n",
    "# Create label\n",
    "label = []\n",
    "for i in range(496):\n",
    "    label.append(0)\n",
    "for i in range(10):\n",
    "    label.append(1)\n",
    "for i in range(495):\n",
    "    label.append(0)\n",
    "    \n",
    "sigma70[\"labels\"] = [label] * len(sigma70)\n",
    "\n",
    "# Split independent testing dataset\n",
    "ind_sigma70 = sigma70.sample(n=200, random_state=37)\n",
    "train_sigma70 = sigma70[~sigma70.index.isin(ind_sigma70.index)]\n",
    "\n",
    "val_sigma70 = ind_sigma70.sample(n=100, random_state=11)\n",
    "test_sigma70 = ind_sigma70[~ind_sigma70.index.isin(val_sigma70.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e326a",
   "metadata": {},
   "source": [
    "# 2. Import libraries and define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f92996",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f52475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu = 0\n",
    "    \n",
    "BATCH_SIZE = 256 # Batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed59f56c",
   "metadata": {},
   "source": [
    "## Define function used in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b52d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating sliding sequences from the data\n",
    "\n",
    "def sliding(df, random_sampling=False):\n",
    "    negative = []\n",
    "    seqs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        # Negative data\n",
    "        for i in range(0, 371): # 371 sequences\n",
    "            e = i + 150\n",
    "            negative.append(row[\"seq\"][i:e])\n",
    "\n",
    "        for i in range(431, 851): # 420 sequences\n",
    "            e = i + 150\n",
    "            negative.append(row[\"seq\"][i:e])\n",
    "        \n",
    "        if random_sampling == True:\n",
    "            # Random sampling the negative data to 60 sequences\n",
    "            random.seed(idx)\n",
    "            random_negative_seq = random.sample(negative, 60)\n",
    "            for negative_seq in random_negative_seq:\n",
    "                seqs.append(negative_seq)\n",
    "\n",
    "            for i in range(len(random_negative_seq)):\n",
    "                labels.append(label[0:150])\n",
    "        elif random_sampling == False:\n",
    "            random.seed(idx)\n",
    "            random_negative_seq = random.sample(negative, 400)\n",
    "            for negative_seq in random_negative_seq:\n",
    "                seqs.append(negative_seq)\n",
    "\n",
    "            for i in range(len(random_negative_seq)):\n",
    "                labels.append(label[0:150])\n",
    "\n",
    "        # Positive data\n",
    "        for i in range(371, 431): # 60 sequences\n",
    "            e = i + 150\n",
    "            seqs.append(row[\"seq\"][i:e])\n",
    "            labels.append(row[\"labels\"][i:e])\n",
    "\n",
    "    labels_com = []\n",
    "    for lab in labels:\n",
    "        lab = [lab]\n",
    "        lab_arr = np.asarray(lab)\n",
    "        lab_arr = lab_arr.transpose(1,0)\n",
    "        labels_com.append(lab_arr)\n",
    "\n",
    "    return seqs, np.asarray(labels_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81747553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for pytorch\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, seqs, labels, bend_ref):\n",
    "        self.seqs = seqs\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.bend_ref = bend_ref\n",
    "        self.avg_bend = sum(bend_ref.values())/len(bend_ref)\n",
    "        \n",
    "        assert len(self.labels) == len(self.seqs)\n",
    "    \n",
    "    def seq2onehot(self, seq):   \n",
    "        module = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "        promoter_onehot = []\n",
    "        for item in seq:\n",
    "            if item == 't' or item == 'T':\n",
    "                promoter_onehot.append(module[0])\n",
    "            elif item == 'a' or item == 'A':\n",
    "                promoter_onehot.append(module[1])\n",
    "            elif item == 'g' or item == 'G':\n",
    "                promoter_onehot.append(module[2])\n",
    "            elif item == 'c' or item == 'C':\n",
    "                promoter_onehot.append(module[3])\n",
    "            else:\n",
    "                promoter_onehot.append([0,0,0,0])\n",
    "\n",
    "        data = np.array(promoter_onehot)\n",
    "        data = np.float32(data)\n",
    "        data = np.transpose(data, (1,0))\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def energyStacking(self, seq):\n",
    "        energy = []\n",
    "        energy.append(self.avg_energy)\n",
    "        \n",
    "        for i in range(len(seq) - 1):\n",
    "            dimer = ''.join(seq[i:i+2])\n",
    "            dimer_val = self.energy_ref[dimer]\n",
    "            #energy.append(energy[-1] + dimer_val)\n",
    "            energy.append(dimer_val)\n",
    "        \n",
    "        return np.float32(np.array(energy))\n",
    "    \n",
    "    def dnaBendability(self, seq):\n",
    "        bend = []\n",
    "        bend.append(self.avg_bend)\n",
    "        \n",
    "        for i in range(len(seq) - 2):\n",
    "            trimer = ''.join(seq[i:i+3])\n",
    "            trimer_bend = self.bend_ref[trimer]\n",
    "            bend.append(trimer_bend)\n",
    "            \n",
    "        bend.append(self.avg_bend)\n",
    "        \n",
    "        return np.float32(np.array(bend))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        seq = self.seqs[idx]\n",
    "        seq = list(itertools.chain.from_iterable(seq))\n",
    "        onehot = self.seq2onehot(seq)\n",
    "        bend = self.dnaBendability(seq)\n",
    "        seq = np.vstack([onehot, bend])\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        label = np.float32(label)\n",
    "        label = np.transpose(label, (1,0))\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return seq, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for stacked energy and bendability values\n",
    "\n",
    "energy_ref = {'GC': -14.59, 'GT': -10.51, 'AC': -10.51, 'GA': -9.81, 'TC': -9.81, 'CG': -9.69,\n",
    "       'CC': -8.26, 'GG': -8.26, 'AT': -6.57, 'CA': -6.57, 'TG': -6.57, 'CT': -6.78,\n",
    "       'AG': -6.78, 'TT': -5.37, 'AA': -5.37, 'TA': -3.82}\n",
    "energy = -np.array(list(energy_ref.values()))\n",
    "energy_normed = 2*(energy - np.min(energy))/(np.max(energy) - np.min(energy)) - 1\n",
    "energy_ref_normed = dict(zip(energy_ref.keys(), energy_normed))\n",
    "\n",
    "bendability_ref = {'AAT': -0.28, 'AAA': -0.274, 'CCA': -0.246, 'AAC': -0.205, 'ACT': -0.183, 'CCG': -0.136,\n",
    "    'ATC': -0.11, 'AAG': -0.081, 'CGC': -0.077, 'AGG': -0.057, 'GAA': -0.037, 'ACG': -0.033,\n",
    "    'ACC': -0.032, 'GAC': -0.013, 'CCC': -0.012, 'ACA': -0.006, 'CGA': -0.003, 'GGA': 0.013,\n",
    "    'CAA': 0.015, 'AGC': 0.017, 'GTA': 0.025, 'AGA': 0.027, 'CTC': 0.031, 'CAC': 0.04,\n",
    "    'TAA': 0.068, 'GCA': 0.076, 'CTA': 0.09, 'GCC': 0.107, 'ATG': 0.134, 'CAG': 0.175,\n",
    "    'ATA': 0.182, 'TCA': 0.194, 'ATT': -0.28, 'TTT': -0.274, 'TGG': -0.246, 'GTT': -0.205,\n",
    "    'AGT': -0.183, 'CGG': -0.136, 'GAT': -0.11, 'CTT': -0.081, 'GCG': -0.077, 'CCT': -0.057,\n",
    "    'TTC': -0.037, 'CGT': -0.033, 'GGT': -0.032, 'GTC': -0.013, 'GGG': -0.012, 'TGT': -0.006,\n",
    "    'TCG': -0.003, 'TCC': 0.013, 'TTG': 0.015, 'GCT': 0.017, 'TAC': 0.025, 'TCT': 0.027,\n",
    "    'GAG': 0.031, 'GTG': 0.04, 'TTA': 0.068, 'TGC': 0.076, 'TAG': 0.09, 'GGC': 0.107,\n",
    "    'CAT': 0.134, 'CTG': 0.175, 'TAT': 0.182, 'TGA': 0.194}\n",
    "\n",
    "bendability = np.array(list(bendability_ref.values()))\n",
    "bendability_normed = 2*(bendability - np.min(bendability))/(np.max(bendability) - np.min(bendability)) - 1\n",
    "bendability_ref_normed = dict(zip(bendability_ref.keys(), bendability_normed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(tp, fp, tn, fn):\n",
    "    acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "    recall = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    f1 = 2*tp/(2*tp+fp+fn)\n",
    "    mcc = (tp*tn-fp*fn)/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    return acc, spec, recall, f1, mcc\n",
    "\n",
    "def evaluate_model(model, dataset, dataloader, threshold=0.05):\n",
    "    recon_data = []\n",
    "    recon_conf_data = []\n",
    "    labels = []\n",
    "    with torch.no_grad():    \n",
    "        for i, (x, x_label) in enumerate(dataloader):\n",
    "            x = x.cuda()\n",
    "            recon, recon_conf = model(x)\n",
    "            if i == 0:\n",
    "                recon_data = recon.cpu().numpy()\n",
    "            else:\n",
    "                recon_data = np.vstack((recon_data, recon.cpu().numpy()))\n",
    "    \n",
    "    for i in range(len(recon_data)):\n",
    "        recon_data[i][recon_data[i] >= threshold] = 1\n",
    "        recon_data[i][recon_data[i] < threshold] = 0\n",
    "    \n",
    "    pos_list = []\n",
    "    neg_list = []\n",
    "    correct_neg = 0\n",
    "    correct_pos = 0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        if sum(dataset[i][1][0].detach().numpy()) == 0.0:\n",
    "            neg_list.append(i)\n",
    "            if sum(recon_data[i][0]) == 0.0:\n",
    "                correct_neg += 1\n",
    "        else:\n",
    "            pos_list.append(i)\n",
    "            if sum(recon_data[i][0]) != 0.0:\n",
    "                correct_pos += 1\n",
    "                \n",
    "    fn = len(pos_list) - correct_pos\n",
    "    fp = len(neg_list) - correct_neg\n",
    "    \n",
    "    return evaluation_metrics(correct_pos, fp, correct_neg, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f33c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal loss used in the training process\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=.2, gamma=3., reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "#         self.alpha = torch.tensor([alpha, 1-alpha]).cuda()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, recon_x, x):\n",
    "        # Calculate BCE loss\n",
    "        BCE_loss = F.binary_cross_entropy(recon_x, x)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        # p = torch.sigmoid(recon_x)\n",
    "        # pt = p * x + (1 - p) * (1 - x)\n",
    "        # pt = recon_x * x + (1 - recon_x) * (1 - x)\n",
    "        F_loss = (1-pt)**self.gamma * BCE_loss\n",
    "    \n",
    "        if self.alpha > 0:\n",
    "            at = self.alpha * x + (1 - self.alpha) * (1 - x)\n",
    "            F_loss = at * F_loss\n",
    "        \n",
    "        if self.reduction == \"mean\":\n",
    "            F_loss = F_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            F_loss = F_loss.sum()\n",
    "        \n",
    "        return F_loss\n",
    "\n",
    "criterion = FocalLoss()\n",
    "\n",
    "class_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)\n",
    "    \n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, seq_length=150):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels*4\n",
    "        \n",
    "        self.doubleConv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, in_channels, kernel_size=7, padding=3, groups=in_channels), # The sequence length will remain the same\n",
    "            nn.LayerNorm(normalized_shape=[in_channels, seq_length]),\n",
    "            nn.Conv1d(in_channels, mid_channels, kernel_size=7, padding=3),\n",
    "            nn.Conv1d(mid_channels, out_channels, kernel_size=7, padding=3), # The sequence length will remain the same\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.doubleConv(x)\n",
    "\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downsampling using maxpooling, followed by 2 layers of convolution\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, special=False, seq_length=150):\n",
    "        super().__init__()\n",
    "        if not special:\n",
    "            self.maxpoolConv = nn.Sequential(\n",
    "                nn.MaxPool1d(2),\n",
    "                DoubleConv(in_channels, out_channels, mid_channels, seq_length)\n",
    "            )\n",
    "        else:\n",
    "            self.maxpoolConv = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=1), \n",
    "                DoubleConv(in_channels, out_channels, mid_channels, seq_length)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.maxpoolConv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling (with skip connection) then 2 conv layers\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, special=False, seq_length=150):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not special:\n",
    "            self.up = nn.ConvTranspose1d(in_channels, in_channels // 2, kernel_size=2, stride=2) \n",
    "            self.conv = DoubleConv(in_channels, out_channels, mid_channels=mid_channels, seq_length=seq_length)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose1d(in_channels, in_channels // 2, kernel_size=3, stride=2, padding=1) #[256, 38] -> [128, 75]\n",
    "            self.conv = DoubleConv(in_channels, out_channels, mid_channels=mid_channels, seq_length=seq_length) #[256, 38] -> [128, 75]\n",
    "            \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1) # [128, 75]\n",
    "        x = torch.cat([x2, x1], dim=1) # [256, 75]\n",
    "        return self.conv(x)\n",
    "        \n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, 64)\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.relu1 = nn.GELU()\n",
    "        self.linear2 = nn.Linear(64, out_dim)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Unet1D(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(Unet1D, self).__init__()\n",
    "                \n",
    "        self.inConv = DoubleConv(n_channels, 32) # (150+2*1-3)/1+1 = 150 (4 -> 32)\n",
    "        self.selayer1 = SELayer(32)\n",
    "        self.down1 = Down(32, 64, seq_length=75) # (Maxpooling -> 75) (32 -> 64)\n",
    "        self.selayer2 = SELayer(64)\n",
    "        self.down2 = Down(64, 128, special=True, seq_length=38) # (Maxpooling -> 38) (64 -> 128)\n",
    "        self.selayer3 = SELayer(128)\n",
    "        self.down3 = Down(128, 256, seq_length=19) # (Maxpooling -> 19) (128 -> 256)\n",
    "        \n",
    "        self.up1 = Up(256, 128, mid_channels=512, seq_length=38) # (ConvTranspose -> 38) (256 -> 128)\n",
    "        self.up2 = Up(128, 64, mid_channels=256, special=True, seq_length=75) # (ConvTranspose -> 75) (128 -> 64)\n",
    "        self.up3 = Up(64, 32, mid_channels=128) # (ConvTranspose -> 150) (64 -> 32)\n",
    "        self.outConv = OutConv(32, n_classes)\n",
    "        self.classConv = MLP(150, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.inConv(x) # [x, 32, 150]\n",
    "        x1 = self.selayer1(x1)\n",
    "        x2 = self.down1(x1) # [x, 64, 75]\n",
    "        x2 = self.selayer2(x2)\n",
    "        x3 = self.down2(x2) # [x, 128, 38]\n",
    "        x3 = self.selayer3(x3)\n",
    "        x4 = self.down3(x3) # [x, 256, 19]\n",
    "        \n",
    "        x = self.up1(x4, x3) # [x, 128, 38]\n",
    "        x = self.up2(x, x2) # [x, 64, 75]\n",
    "        x = self.up3(x, x1) # [x, 32, 150]\n",
    "        out = self.outConv(x) # [x, 1, 150]\n",
    "        #out = torch.sigmoid(out)\n",
    "        #out_conf = self.classConv(out.view(out.size()[0], -1))\n",
    "        out_conf = self.classConv(out.squeeze(1))\n",
    "        return (torch.sigmoid(out), torch.sigmoid(out_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281ab7d",
   "metadata": {},
   "source": [
    "# 3. Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8a77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test the model's performance on the test set\n",
    "unet = Unet1D(5, 1)\n",
    "unet.cuda()\n",
    "test_seqs, test_labels = sliding(test_sigma70, random_sampling=True)\n",
    "\n",
    "test_set = SeqDataset(test_seqs, test_labels, bendability_ref_normed)\n",
    "test_dl = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = \"model_weights/best_model_BEND_K7.pt\" # Load the trained weights\n",
    "unet.load_state_dict(torch.load(model))\n",
    "unet.eval()\n",
    "\n",
    "recon_data = []\n",
    "recon_conf_data = []\n",
    "labels = []\n",
    "with torch.no_grad():    \n",
    "    for i, (x, x_label) in enumerate(test_dl):\n",
    "        x = x.cuda()\n",
    "        recon, recon_conf = unet(x)\n",
    "        if i == 0:\n",
    "            recon_data = recon.cpu().numpy()\n",
    "            for i in np.argmax(recon_conf.cpu().numpy(), axis = 1).tolist():\n",
    "                recon_conf_data.append(i)\n",
    "            for i in torch.squeeze(torch.sum(x_label, dim = -1)).numpy().tolist():\n",
    "                labels.append(i)\n",
    "        else:\n",
    "            recon_data = np.vstack((recon_data, recon.cpu().numpy()))\n",
    "            for i in np.argmax(recon_conf.cpu().numpy(), axis = 1).tolist():\n",
    "                recon_conf_data.append(i)\n",
    "            for i in torch.squeeze(torch.sum(x_label, dim = -1)).numpy().tolist():\n",
    "                labels.append(i)\n",
    "\n",
    "for thres in np.linspace(0.01, 0.30, num=30):\n",
    "    pred = recon_data.copy()\n",
    "\n",
    "    for i in range(len(recon_data)):\n",
    "        pred[i][pred[i] >= thres] = 1\n",
    "        pred[i][pred[i] < thres] = 0\n",
    "\n",
    "    pos_list = []\n",
    "    neg_list = []\n",
    "    correct_neg = 0\n",
    "    correct_pos = 0\n",
    "\n",
    "    for i in range(len(test_set)):\n",
    "        if sum(test_set[i][1][0].detach().numpy()) == 0.0:\n",
    "            neg_list.append(i)\n",
    "            if sum(pred[i][0]) == 0.0:\n",
    "                correct_neg += 1\n",
    "        else:\n",
    "            pos_list.append(i)\n",
    "            if sum(pred[i][0]) != 0.0:\n",
    "                correct_pos += 1\n",
    "\n",
    "    fn = len(pos_list) - correct_pos\n",
    "    fp = len(neg_list) - correct_neg\n",
    "    print(correct_pos, fp, correct_neg, fn)\n",
    "\n",
    "    acc, spec, recall, f1, mcc = evaluation_metrics(correct_pos, fp, correct_neg, fn)\n",
    "    print(\"Threshold: {}, Acc: {:.3f}, Specificity: {:.3f}, Sensitivity: {:.3f}, F1: {:.3f}, MCC: {:.3f}\".format(thres, acc, spec, recall, f1, mcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred = recon_data.copy()\n",
    "            \n",
    "for i in range(len(pred)):\n",
    "    pred[i][pred[i] >= 0.13] = 1\n",
    "    pred[i][pred[i] < 0.13] = 0\n",
    "    \n",
    "pos_list = []\n",
    "pos_id = []\n",
    "correct_pos = 0\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    if sum(test_set[i][1][0].detach().numpy()) != 0.0:\n",
    "        pos_list.append(i)\n",
    "        if sum(pred[i][0]) != 0.0:\n",
    "            pos_id.append(i)\n",
    "            correct_pos += 1\n",
    "\n",
    "print(correct_pos)\n",
    "print(correct_pos/len(pos_list))\n",
    "\n",
    "neg_list = []\n",
    "neg_id = []\n",
    "correct_pos = 0\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    if sum(test_set[i][1][0].detach().numpy()) == 0.0:\n",
    "        neg_list.append(i)\n",
    "        if sum(pred[i][0]) == 0.0:\n",
    "            neg_id.append(i)\n",
    "            correct_pos += 1\n",
    "\n",
    "print(correct_pos)\n",
    "print(correct_pos/len(neg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28632c34",
   "metadata": {},
   "source": [
    "## Calculate distance to the real TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for i in pos_id:\n",
    "    pred_pos = np.argmax(recon_data[i][0])\n",
    "    real_pos = np.argmax(test_set[i][1][0].numpy())\n",
    "    distances.append(np.absolute(pred_pos - real_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.histplot(distances, bins=100)\n",
    "ax.set(xlabel='Distance')\n",
    "\n",
    "# plt.savefig(\"Distance_Distribution.pdf\", format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(distances, hist=True, kde=True,  \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'color': 'red'})\n",
    "\n",
    "ax.set(xlabel='Distance')\n",
    "\n",
    "# plt.savefig(\"Distance_Distribution_Hist_KDE.pdf\", format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d46d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(distances, hist=False, kde=True,  \n",
    "             kde_kws={'color': 'red'})\n",
    "\n",
    "ax.set(xlabel='Distance')\n",
    "\n",
    "# plt.savefig(\"Distance_Distribution_KDE.pdf\", format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(distances, hist=True, kde=True,  \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'color': 'red', 'cumulative': True})\n",
    "\n",
    "ax.set(xlabel='Distance')\n",
    "\n",
    "# plt.savefig(\"Distance_Distribution_Hist_Cumulative.pdf\", format=\"pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1486be2",
   "metadata": {},
   "source": [
    "# Consensus score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00efffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86421d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sigma70 = sigma70[sigma70[\"express\"] != \"Weak\"]\n",
    "f_sigma70.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding = {}\n",
    "for i, row in f_sigma70.iterrows():\n",
    "    sliding[row[\"name\"]] = {}\n",
    "    idx = 0\n",
    "    for j in range(0, 851):\n",
    "        sub_seq = row['seq'][j:j+150]\n",
    "        sliding[row[\"name\"]][idx] = sub_seq\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d26121",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bend = sum(bendability_ref_normed.values())/len(bendability_ref_normed)\n",
    "\n",
    "def seq2onehot(seq):   \n",
    "    module = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "    promoter_onehot = []\n",
    "    for item in seq:\n",
    "        if item == 't' or item == 'T':\n",
    "            promoter_onehot.append(module[0])\n",
    "        elif item == 'a' or item == 'A':\n",
    "            promoter_onehot.append(module[1])\n",
    "        elif item == 'g' or item == 'G':\n",
    "            promoter_onehot.append(module[2])\n",
    "        elif item == 'c' or item == 'C':\n",
    "            promoter_onehot.append(module[3])\n",
    "        else:\n",
    "            promoter_onehot.append([0,0,0,0])\n",
    "\n",
    "    data = np.array(promoter_onehot)\n",
    "    data = np.float32(data)\n",
    "    data = np.transpose(data, (1,0))\n",
    "\n",
    "    return data\n",
    "\n",
    "def dnaBendability(seq):\n",
    "    bend = []\n",
    "    bend.append(avg_bend)\n",
    "\n",
    "    for i in range(len(seq) - 2):\n",
    "        trimer = ''.join(seq[i:i+3])\n",
    "        trimer_bend = bendability_ref_normed[trimer]\n",
    "        bend.append(trimer_bend)\n",
    "\n",
    "    bend.append(avg_bend)\n",
    "\n",
    "    return np.float32(np.array(bend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015649ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "for s in sliding:\n",
    "    with torch.no_grad():\n",
    "        overall_score = np.zeros(1001)\n",
    "        scores = np.ones(150)\n",
    "        \n",
    "        for i in sliding[s]:\n",
    "            seq = list(itertools.chain.from_iterable(sliding[s][i]))\n",
    "            onehot = seq2onehot(seq)\n",
    "            bend = dnaBendability(seq)\n",
    "            seq = np.vstack([onehot, bend])\n",
    "            seq = np.reshape(seq, (1,5,150))\n",
    "            seq = torch.tensor(seq)\n",
    "\n",
    "            recon, recon_conf = unet(seq.cuda())\n",
    "            recon = recon.cpu().numpy()\n",
    "            max_pos = np.argmax(recon)\n",
    "            for pos in range(max_pos-5, max_pos+5):\n",
    "                if pos >= 150:\n",
    "                    pos = 149\n",
    "                elif pos < 0:\n",
    "                    pos = 0\n",
    "                scores[pos] = 5\n",
    "            scores[max_pos] = 10\n",
    "            overall_score[i:i+150] += scores\n",
    "        # print(np.argmax(overall_score))\n",
    "        score_dict[s] = overall_score.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39123901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(score_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcd6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Predicted_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36856aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=0).plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame(df.mean(axis=0))\n",
    "plot_data[\"pos\"] = plot_data.index\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.rename(columns = {0: \"Mean score\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc08cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_data.iloc[400:601, :].plot(title=\"Mean confidence score\")\n",
    "ax.set_xlabel(\"Position\")\n",
    "ax.set_ylabel(\"Confidence score\")\n",
    "plt.xticks(list(range(0,201,25)), list(range(-100,101,25)))\n",
    "plt.savefig(\"Mean_confidence_score.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76e866",
   "metadata": {},
   "source": [
    "# Sliding aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14671063",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_sigma70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding = {}\n",
    "for i, row in ind_sigma70.iterrows():\n",
    "    sliding[row[\"name\"]] = {}\n",
    "    idx = 0\n",
    "    for j in range(371, 431):\n",
    "        sub_seq = row['seq'][j:j+150]\n",
    "        sliding[row[\"name\"]][idx] = sub_seq\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387dd474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cmd = \"rm *Stacked_Prediction.pdf\"\n",
    "os.system(cmd)\n",
    "\n",
    "label = []\n",
    "for i in range(130):\n",
    "    label.append(0)\n",
    "label.append(1)\n",
    "for i in range(79):\n",
    "    label.append(0)\n",
    "\n",
    "for s in sliding:\n",
    "    with torch.no_grad(): \n",
    "        recon_data = []\n",
    "        \n",
    "        for i in sliding[s]:\n",
    "            seq = list(itertools.chain.from_iterable(sliding[s][i]))\n",
    "            onehot = seq2onehot(seq)\n",
    "            bend = dnaBendability(seq)\n",
    "            seq = np.vstack([onehot, bend])\n",
    "            seq = np.reshape(seq, (1,5,150))\n",
    "            seq = torch.tensor(seq)\n",
    "\n",
    "            recon, recon_conf = unet(seq.cuda())\n",
    "            if i == 0:\n",
    "                recon_data = recon.cpu().numpy()\n",
    "            else:\n",
    "                recon_data = np.vstack((recon_data, recon.cpu().numpy()))\n",
    "        pred = recon_data.copy()\n",
    "\n",
    "        for i in range(len(recon_data)):\n",
    "            recon_data[i][recon_data[i] >= 0.13] = 1\n",
    "            recon_data[i][recon_data[i] < 0.13] = 0\n",
    "\n",
    "        fig = plt.figure(figsize = (20, 6))\n",
    "        ax1 = fig.add_subplot(2, 1, 1)\n",
    "        ax1.plot(label)\n",
    "        ax1.set_xticks(range(0,211)[::10])\n",
    "        ax1.set_xticklabels(range(-130,81)[::10])\n",
    "        ax1.title.set_text(s)\n",
    "           \n",
    "        ax2 = fig.add_subplot(2, 1, 2)\n",
    "        for j in range(recon_data.shape[0]):\n",
    "            x1 = np.linspace(j, j + 150, 150)\n",
    "            y1 = [recon_data.shape[0] - j] * 150\n",
    "            if np.sum(recon_data[j]) != 0:\n",
    "                plt.plot(x1, y1, color = 'red')\n",
    "                pred_pos = np.argmax(pred[j])\n",
    "                x2 = x1[pred_pos]\n",
    "                y2 = recon_data.shape[0] - j\n",
    "                ax2.plot(x2, y2, color = 'green', marker = '.', markersize = 10)\n",
    "            else:\n",
    "                ax2.plot(x1, y1, color = 'black')\n",
    "        ax2.set_xticks(range(0,211)[::10])\n",
    "        ax2.set_xticklabels(range(-130,81)[::10])\n",
    "        \n",
    "        fileName = \"Sample_\" + str(s) + \"_Stacked_Prediction.pdf\"\n",
    "        plt.savefig(fileName, format=\"pdf\")\n",
    "        plt.show()\n",
    "\n",
    "cmd = \"mkdir Stacked_Images\"\n",
    "os.system(cmd)\n",
    "cmd = \"mv *Stacked_Prediction.pdf Stacked_Images\"\n",
    "os.system(cmd)\n",
    "cmd = \"tar -zcvf Stacked_Images.tar.gz Stacked_Images\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    recon_data = []\n",
    "    for i in sliding[\"ECK125137306\"]:\n",
    "        seq = list(itertools.chain.from_iterable(sliding[\"ECK125137306\"][i]))\n",
    "        onehot = seq2onehot(seq)\n",
    "        bend = dnaBendability(seq)\n",
    "        seq = np.vstack([onehot, bend])\n",
    "        seq = np.reshape(seq, (1,5,150))\n",
    "        seq = torch.tensor(seq)\n",
    "\n",
    "        recon, recon_conf = unet(seq.cuda())\n",
    "        if i == 0:\n",
    "            recon_data = recon.cpu().numpy()\n",
    "        else:\n",
    "            recon_data = np.vstack((recon_data, recon.cpu().numpy()))\n",
    "    \n",
    "    pred = recon_data.copy()\n",
    "    for i in range(len(recon_data)):\n",
    "        recon_data[i][recon_data[i] >= 0.13] = 1\n",
    "        recon_data[i][recon_data[i] < 0.13] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {}\n",
    "for i in range(recon_data.shape[0]):\n",
    "    start = -130 + i\n",
    "    pos = np.argmax(pred[i]) + start\n",
    "    if pos not in positions:\n",
    "        positions[pos] = 1\n",
    "    else:\n",
    "        positions[pos] += 1\n",
    "        \n",
    "print({key: value for key, value in sorted(positions.items())}, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312d030",
   "metadata": {},
   "source": [
    "# Full length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ce66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sigma70[test_sigma70[\"name\"] == \"ECK125136473\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93975c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sigma70[\"name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding = {}\n",
    "for i, row in test_sigma70.iterrows():\n",
    "    sliding[row[\"name\"]] = {}\n",
    "    idx = 0\n",
    "    for j in range(301, 651):\n",
    "        sub_seq = row['seq'][j:j+150]\n",
    "        sliding[row[\"name\"]][idx] = sub_seq\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding[\"ECK120009948\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ade954",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sliding[\"ECK120033681\"]\n",
    "recon_data = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i in test:\n",
    "        seq = list(itertools.chain.from_iterable(test[i]))\n",
    "        onehot = seq2onehot(seq)\n",
    "        bend = dnaBendability(seq)\n",
    "        seq = np.vstack([onehot, bend])\n",
    "        seq = np.reshape(seq, (1,5,150))\n",
    "        seq = torch.tensor(seq)\n",
    "\n",
    "        recon, recon_conf = unet(seq.cuda())\n",
    "        if i == 0:\n",
    "            recon_data = recon.cpu().numpy()\n",
    "        else:\n",
    "            recon_data = np.vstack((recon_data, recon.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fe74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(recon_data)):\n",
    "    recon_data[i][recon_data[i] >= 0.13] = 1\n",
    "    recon_data[i][recon_data[i] < 0.13] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros(501)\n",
    "label[47] = 1\n",
    "label[74] = 1\n",
    "label[138] = 1\n",
    "label[200] = 1\n",
    "label[207] = 1\n",
    "label[320] = 1\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(label)\n",
    "plt.subplot(2, 1, 2)\n",
    "for j in range(recon_data.shape[0]):\n",
    "    x1 = np.linspace(j, j + 150, 150)\n",
    "    y1 = [recon_data.shape[0] - j] * 150\n",
    "    if np.sum(recon_data[j]) != 0:\n",
    "        plt.plot(x1, y1, color = 'red')\n",
    "        pred_pos = np.argmax(recon_data[j])\n",
    "        x2 = x1[pred_pos]\n",
    "        y2 = recon_data.shape[0] - j\n",
    "        plt.plot(x2, y2, color = 'green', marker = '.', markersize = 10)\n",
    "    else:\n",
    "        plt.plot(x1, y1, color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sliding[\"ECK125136473\"]\n",
    "recon_data = []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for i in test:\n",
    "        seq = list(itertools.chain.from_iterable(test[i]))\n",
    "        onehot = seq2onehot(seq)\n",
    "        bend = dnaBendability(seq)\n",
    "        seq = np.vstack([onehot, bend])\n",
    "        seq = np.reshape(seq, (1,5,150))\n",
    "        seq = torch.tensor(seq)\n",
    "\n",
    "        recon, recon_conf = unet(seq.cuda())\n",
    "        if i == 0:\n",
    "            recon_data = recon.cpu().numpy()\n",
    "        else:\n",
    "            recon_data = np.vstack((recon_data, recon.cpu().numpy()))\n",
    "            \n",
    "for i in range(len(recon_data)):\n",
    "    recon_data[i][recon_data[i] >= 0.13] = 1\n",
    "    recon_data[i][recon_data[i] < 0.13] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros(501)\n",
    "label[200] = 1\n",
    "label[307] = 1\n",
    "\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.text(160, 1.2, \"ECK125136473\", fontsize = 20)\n",
    "plt.text(265, 1.2, \"ECK125257034\", fontsize = 20)\n",
    "plt.plot(label)\n",
    "plt.subplot(2, 1, 2)\n",
    "for j in range(recon_data.shape[0]):\n",
    "    x1 = np.linspace(j, j + 150, 150)\n",
    "    y1 = [recon_data.shape[0] - j] * 150\n",
    "    if np.sum(recon_data[j]) != 0:\n",
    "        plt.plot(x1, y1, color = 'red')\n",
    "        pred_pos = np.argmax(recon_data[j])\n",
    "        x2 = x1[pred_pos]\n",
    "        y2 = recon_data.shape[0] - j\n",
    "        plt.plot(x2, y2, color = 'green', marker = '.', markersize = 10)\n",
    "    else:\n",
    "        plt.plot(x1, y1, color = 'black')\n",
    "        \n",
    "plt.savefig(\"ECK125136473_500.pdf\", format=\"pdf\")\n",
    "plt.show(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb23633",
   "metadata": {},
   "source": [
    "# Aggregation -75 +75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48052ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sigma70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding = {}\n",
    "for i, row in test_sigma70.iterrows():\n",
    "    sliding[row[\"name\"]] = row['seq'][425:575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef06047",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(75):\n",
    "    label.append(0)\n",
    "label.append(1)\n",
    "for i in range(74):\n",
    "    label.append(0)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    recon_data = []\n",
    "    for s in sliding:\n",
    "        seq = list(itertools.chain.from_iterable(sliding[s]))\n",
    "        onehot = seq2onehot(seq)\n",
    "        bend = dnaBendability(seq)\n",
    "        seq = np.vstack([onehot, bend])\n",
    "        seq = np.reshape(seq, (1,5,150))\n",
    "        seq = torch.tensor(seq)\n",
    "\n",
    "        recon, recon_conf = unet(seq.cuda())\n",
    "\n",
    "        if s == \"ECK120009948\":\n",
    "            recon_data = recon.cpu().numpy()\n",
    "        else:\n",
    "            recon_data = np.vstack((recon_data, recon.cpu().numpy()))\n",
    "    \n",
    "    for i in range(len(recon_data)):\n",
    "        recon_data[i][recon_data[i] >= 0.13] = 1\n",
    "        recon_data[i][recon_data[i] < 0.13] = 0\n",
    "        \n",
    "def sortList(arr):\n",
    "    return np.sum(arr)\n",
    "\n",
    "recon_data_sorted = np.array(sorted(recon_data, key = sortList, reverse=True))\n",
    "pred = recon_data_sorted.copy()\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(20,4))\n",
    "ax.title.set_text(\"TSS position identification\")\n",
    "for j in range(recon_data_sorted.shape[0]):\n",
    "    x1 = np.linspace(0, 0 + 150, 150)\n",
    "    y1 = [recon_data_sorted.shape[0] - j] * 150\n",
    "    if np.sum(recon_data_sorted[j]) != 0:\n",
    "        ax.plot(x1, y1, color = 'red')\n",
    "        pred_pos = np.argmax(pred[j])\n",
    "        x2 = x1[pred_pos]\n",
    "        y2 = recon_data_sorted.shape[0] - j\n",
    "        ax.plot(x2, y2, color = 'green', marker = '.', markersize = 10)\n",
    "    else:\n",
    "        ax.plot(x1, y1, color = 'black')\n",
    "ax.set_xticks(range(0,150)[::10])\n",
    "ax.set_xticklabels(range(-75,75)[::10])\n",
    "\n",
    "fileName = \"Stacked_Testset_Pred.pdf\"\n",
    "plt.savefig(fileName, format=\"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
